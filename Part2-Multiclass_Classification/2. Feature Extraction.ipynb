{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ed36152-98ef-40a1-a439-93961c29d3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import librosa.display\n",
    "import soundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f8ecdb-4b58-4366-955e-d0e9b752ad49",
   "metadata": {},
   "source": [
    "# Wrap related functions into a file: src/feature_extraction.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2623e8-7e8a-4e50-bac9-087364cb4fbb",
   "metadata": {},
   "source": [
    "```python\n",
    "# Classes in the dataset\n",
    "activities ={\n",
    "  '1_uncap_':1,\n",
    "  '2_click_':2,\n",
    "  '3_exhale_out_':3,\n",
    "  '4_inhale_':4,\n",
    "  '5_exhale_into_':5,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96dee52-d780-4e76-9dfc-c3ecfe8a94de",
   "metadata": {},
   "source": [
    "# 1. Have a look at the feature dimentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a55cee7f-07eb-4d4e-8ade-eb2ae2d8afb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature_extraction import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19e8ee9d-6efe-4b55-9334-877f5303deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a sample\n",
    "with soundfile.SoundFile( r'..\\0. Data\\4. Segments_5_classes\\2_click_6.wav') as audio:\n",
    "    waveform = audio.read(dtype='float32')\n",
    "    sample_rate = audio.samplerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3a1e09e-2521-42b4-9773-e91e505dd03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ziyif\\miniconda3\\envs\\sklearn\\lib\\site-packages\\librosa\\feature\\spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "spectrogram = feature_spectrogram(waveform, sample_rate)\n",
    "spectrogram_mean = feature_spectrogram_mean(waveform, sample_rate)\n",
    "centroid = feature_centroid(waveform, sample_rate)\n",
    "bandwidth = feature_bandwidth(waveform, sample_rate)\n",
    "# upper_bound = centroid[0] + bandwidth[0]\n",
    "# lower_bound = centroid[0] - bandwidth[0]\n",
    "melspectrogram = feature_melspectrogram(waveform, sample_rate)\n",
    "melspectrogram_mean = feature_melspectrogram_mean(waveform, sample_rate)\n",
    "mfcc = feature_mfcc(waveform, sample_rate)\n",
    "chromagram = feature_chromagram(waveform, sample_rate)\n",
    "chromagram_mean = feature_chromagram_mean(waveform, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64a5e2d1-185f-4f7e-8a32-07d9da589d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025, 63)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73c863ec-75e2-45d4-8811-699dfc12ab47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrogram_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d72b5335-00a7-4bb6-a517-e118b79597ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 63)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c595af01-e87d-49ae-aa82-24f566bcee2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 63)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandwidth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "511168ea-811e-4dc1-869c-8706afa9983b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 63)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melspectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e1f9478-4637-44ff-860e-09b9bb7bb711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melspectrogram_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7acca746-be12-401d-9a37-ce56bc39fbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3883b3a-82e5-4343-86b6-81852e8e7717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 63)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chromagram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a79999a5-59d5-4c99-b583-9054f9e1412d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chromagram_mean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08127fb4-4152-4d61-bf50-bea2c5acee7b",
   "metadata": {},
   "source": [
    "# 2. Scaling, splitting and save the features\n",
    "\n",
    "Data Split & Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bf5fa27-89c9-4fd4-a81c-0a13d11f643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a7ea07-e7e5-4685-9c7a-747f743573d9",
   "metadata": {},
   "source": [
    "## 2.1 Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0616dc72-9fd0-4d93-9caf-ff2cee253986",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract activity\n",
    "def load_data(feature_set_number):\n",
    "    data_folder = r'..\\0. Data\\4. Segments_5_classes' \n",
    "    X, y = [], []\n",
    "    count = 0\n",
    "\n",
    "    # Activity mapping table (ensure suffix has \"_\" to avoid misidentification)\n",
    "    activities = {\n",
    "        '1_uncap_': 1,\n",
    "        '2_click_': 2,\n",
    "        '3_exhale_out_': 3,\n",
    "        '4_inhale_': 4,\n",
    "        '5_exhale_into_': 5,\n",
    "    }\n",
    "\n",
    "    for file in glob.glob(os.path.join(data_folder, \"*.wav\")):\n",
    "        file_name = os.path.basename(file)\n",
    "\n",
    "        # Automatically match activity prefix\n",
    "        activity = None\n",
    "        for prefix in activities:\n",
    "            if file_name.startswith(prefix):\n",
    "                activity = activities[prefix]\n",
    "                break\n",
    "        if activity is None:\n",
    "            print(f\"‚ö†Ô∏è Skipping unrecognized file: {file_name}\")\n",
    "            continue\n",
    "\n",
    "        # Extract features\n",
    "        if feature_set_number == 6:\n",
    "            features = create_feature_set_6(file)\n",
    "        else:\n",
    "            raise ValueError(\"‚ùå Invalid feature_set_number. Must be 1-6.\")\n",
    "\n",
    "        X.append(features)\n",
    "        y.append(activity)\n",
    "        count += 1\n",
    "        print('\\r' + f'üîÑ Processed {count} audio samples', end='')\n",
    "\n",
    "    print(\"\\n‚úÖ Data loading complete.\")\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e821b6-9080-43bd-aa20-a9788378160d",
   "metadata": {},
   "source": [
    "## 2.1.6 Feature set 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14af3740-b660-460b-bcab-028e190cebbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ziyif\\miniconda3\\envs\\sklearn\\lib\\site-packages\\librosa\\feature\\spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Processed 540 audio samples\n",
      "‚úÖ Data loading complete.\n",
      "Train and Test Size 432, 108\n",
      "Feature set shape:  (432, 1331)\n"
     ]
    }
   ],
   "source": [
    "X,y = load_data(feature_set_number=6)\n",
    "\n",
    "X_train_6, X_test_6, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# Output the train and test data size and shape\n",
    "print(f\"Train and Test Size {len(X_train_6)}, {len(X_test_6)}\")\n",
    "print(\"Feature set shape: \", X_train_6.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab50df7-da60-488b-9f2c-6c301e307b3d",
   "metadata": {},
   "source": [
    "## 2.2 Save all feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "539b1c77-0000-44ac-8b8c-77c29f486e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "\n",
    "X_train_6 = pd.DataFrame(X_train_6)\n",
    "X_test_6 = pd.DataFrame(X_test_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d311e4f-7f38-4541-bec5-3ea45a1d31fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\Users\\ziyif\\OneDrive\\ÊñáÊ°£\\GitHub\\ML-Acoustic-DPI-Adherence\\Features\\y_train.csv, saved\n",
      "File: C:\\Users\\ziyif\\OneDrive\\ÊñáÊ°£\\GitHub\\ML-Acoustic-DPI-Adherence\\Features\\y_test.csv, saved\n",
      "File: C:\\Users\\ziyif\\OneDrive\\ÊñáÊ°£\\GitHub\\ML-Acoustic-DPI-Adherence\\Features\\X_train_6.csv, saved\n",
      "File: C:\\Users\\ziyif\\OneDrive\\ÊñáÊ°£\\GitHub\\ML-Acoustic-DPI-Adherence\\Features\\X_test_6.csv, saved\n"
     ]
    }
   ],
   "source": [
    "# Save the data to Excel\n",
    "data_path = r'..\\Features'\n",
    "\n",
    "# Check if the directory exists, if not, create it\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "\n",
    "# Save to csv files\n",
    "file_path = os.path.join(data_path, 'y_train.csv')\n",
    "y_train.to_csv(file_path)\n",
    "print(f\"File: {file_path}, saved\")\n",
    "\n",
    "file_path = os.path.join(data_path, 'y_test.csv')\n",
    "y_test.to_csv(file_path)\n",
    "print(f\"File: {file_path}, saved\")\n",
    "\n",
    "file_path = os.path.join(data_path, 'X_train_6.csv')\n",
    "X_train_6.to_csv(file_path)\n",
    "print(f\"File: {file_path}, saved\")\n",
    "\n",
    "file_path = os.path.join(data_path, 'X_test_6.csv')\n",
    "X_test_6.to_csv(file_path)\n",
    "print(f\"File: {file_path}, saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b982a79c-12b1-4e95-ae96-410e1d7e25e7",
   "metadata": {},
   "source": [
    "# Wrap datasets into a file: src/data_loader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "388eef0c-45b4-4e17-bdca-15514a480dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_loader import load_data\n",
    "\n",
    "# Load the data\n",
    "(y_train, y_test, \n",
    "X_train_6, X_test_6)= load_data(transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d07332dd-188e-4690-88ae-a2035cd17cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4de34856-89a5-4356-a32e-52124642def6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    2\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    4\n",
       "..  ..\n",
       "103  1\n",
       "104  2\n",
       "105  3\n",
       "106  4\n",
       "107  2\n",
       "\n",
       "[108 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
