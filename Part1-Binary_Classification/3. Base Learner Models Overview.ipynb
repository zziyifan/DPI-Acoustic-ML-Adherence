{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "319f96e9-66a3-4786-bed2-fc0d1192d301",
   "metadata": {},
   "source": [
    "# 3. Machine Learning (ML) algorithms Used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebc46db-b850-44eb-b545-c25933a49731",
   "metadata": {},
   "source": [
    "## 3.1 Tree-based ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6d372d-cdc7-4e24-ad3e-157f44dfb369",
   "metadata": {},
   "source": [
    "- DecisionTreeClassifier\r",
    "- \n",
    "ExtraTreeClassifier\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038e654a-26de-45ca-aecb-adc65290f191",
   "metadata": {},
   "source": [
    "## 3.2 Bagging-based ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31810bf0-b18e-4079-98be-d52a4be94ebb",
   "metadata": {},
   "source": [
    "- RandomForestClassifier \n",
    "- ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e835b6f9-70b3-4104-b551-879c0e05e094",
   "metadata": {},
   "source": [
    "## 3.3 Boosting-based ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ba0f5e-dd8a-4d44-8c3c-a1c4151670ec",
   "metadata": {},
   "source": [
    "- AdaBoostClassifier\n",
    "- GradientBoostingClassifier\n",
    "- XGBClassifier\n",
    "- CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cfcec8-0817-43b7-b402-7ad23ffc2fff",
   "metadata": {},
   "source": [
    "## 3.4 Other ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a9ab70-3d46-44dc-a453-0680a1c32956",
   "metadata": {},
   "source": [
    "\n",
    "- Linear_model: LogisticRegression\n",
    "- Naive_bayes: GaussianNB, BernoulliNB\n",
    "- Neighbors: KNeighborsClassifier\n",
    "- GaussianProcessClassifier\n",
    "- SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d145567f-71bf-403b-9aa9-fb38d4fa64a6",
   "metadata": {},
   "source": [
    "# Summarize the libs into a file: `src/config.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bb1b50-e749-40f1-85e4-122b2eef6ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import os, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas_ta as ta\n",
    "from pathlib import Path\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# plotting & outputs\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-bright')\n",
    "pd.set_option(\"display.max_columns\",None)\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix, auc, roc_curve, plot_roc_curve\n",
    "\n",
    "# import classifiers\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import (AdaBoostClassifier,\n",
    "                              RandomForestClassifier, \n",
    "                              ExtraTreesClassifier,\n",
    "                              GradientBoostingClassifier, \n",
    "                              BaggingClassifier,\n",
    "                              VotingClassifier, \n",
    "                              StackingClassifier)\n",
    "\n",
    "from xgboost import XGBClassifier \n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3209d84-abd7-4c09-b672-bb293d4e657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from src.config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24a3be7-837b-471e-ab24-8de83ed72dd0",
   "metadata": {},
   "source": [
    "# Summarize MLFlow logging settings into a file: `src/mlflow_logging.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b3f237-5a5d-4812-9990-26254b28f1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from src.config import *\n",
    "from src.data_loader import load_data\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from itertools import product\n",
    "\n",
    "def train_and_log_model(model_class, param_ranges, feature_set, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Train a model with different hyperparameters using 5-fold cross-validation,\n",
    "    and log the results with MLflow.\n",
    "\n",
    "    Args:\n",
    "        model_class: The model class to be instantiated (e.g., RandomForestClassifier).\n",
    "        param_ranges (dict): A dictionary containing parameter ranges.\n",
    "            Example: {\n",
    "                \"n_estimators_range\": np.arange(100, 200, 2),\n",
    "                \"max_depth_range\": np.arange(1, 5, 2),\n",
    "                \"max_features_range\": [\"sqrt\", \"log2\"]\n",
    "            }\n",
    "        feature_set: in range:[1,2,3,4,5,6].\n",
    "        cv_folds (int): Number of cross-validation folds. Default is 5.\n",
    "        \n",
    "    \"\"\"\n",
    "    best_accuracy_mean = -np.inf\n",
    "    best_model_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    # Load the data\n",
    "    (y_train, y_test, \n",
    "    X_train_1, X_test_1,\n",
    "    X_train_2, X_test_2,\n",
    "    X_train_3, X_test_3,\n",
    "    X_train_4, X_test_4,\n",
    "    X_train_5, X_test_5,\n",
    "    X_train_6, X_test_6)= load_data(transform=True)\n",
    "\n",
    "    if feature_set == 1:\n",
    "        X_train = X_train_1\n",
    "        X_test = X_test_1\n",
    "    elif feature_set == 2:\n",
    "        X_train = X_train_2\n",
    "        X_test = X_test_2\n",
    "    elif feature_set == 3:\n",
    "        X_train = X_train_3\n",
    "        X_test = X_test_3\n",
    "    elif feature_set == 4:\n",
    "        X_train = X_train_4\n",
    "        X_test = X_test_4\n",
    "    elif feature_set == 5:\n",
    "        X_train = X_train_5\n",
    "        X_test = X_test_5\n",
    "    elif feature_set == 6:\n",
    "        X_train = X_train_6\n",
    "        X_test = X_test_6\n",
    "    else:\n",
    "        raise ValueError(\"Invalid feature set specified.\")\n",
    "        \n",
    "    \n",
    "    # set experiment\n",
    "    model_name = model_class.__name__\n",
    "    mlflow.set_experiment(experiment_name = model_name+'_'+feature_set)\n",
    "\n",
    "    # Extract parameter names and values\n",
    "    param_names = list(param_ranges.keys())\n",
    "    param_values = list(param_ranges.values())\n",
    "\n",
    "    # Iterate over all combinations of parameter values\n",
    "    for param_combination in tqdm(list(product(*param_values)), desc=\"Hyperparameter combinations\"):\n",
    "        param_dict = dict(zip(param_names, param_combination))\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            # Initialize the model with the current set of parameters\n",
    "            # model = model_class(**param_dict, n_jobs=-1)\n",
    "            model = model_class(**param_dict)\n",
    "            \n",
    "\n",
    "            # Perform cross-validation\n",
    "            skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "            y_pred_cv = cross_val_predict(model, X_train, y_train, cv=skf)\n",
    "            f1_scores = cross_val_score(model, X_train, y_train, cv=skf, scoring='f1')\n",
    "            accuracy_scores = cross_val_score(model, X_train, y_train, cv=skf, scoring='accuracy')\n",
    "            precision_scores = cross_val_score(model, X_train, y_train, cv=skf, scoring='precision')\n",
    "            recall_scores = cross_val_score(model, X_train, y_train, cv=skf, scoring='recall')\n",
    "            auc_scores = cross_val_score(model, X_train, y_train, cv=skf, scoring='roc_auc')\n",
    "\n",
    "            # Calculate mean and variance of metrics\n",
    "            f1_mean, f1_std = np.mean(f1_scores), np.std(f1_scores)\n",
    "            accuracy_mean, accuracy_std = np.mean(accuracy_scores), np.std(accuracy_scores)\n",
    "            precision_mean, precision_std = np.mean(precision_scores), np.std(precision_scores)\n",
    "            recall_mean, recall_std = np.mean(recall_scores), np.std(recall_scores)\n",
    "            auc_mean, auc_std = np.mean(auc_scores), np.std(auc_scores)\n",
    "\n",
    "            # Log parameters\n",
    "            mlflow.log_params(param_dict)\n",
    "            # Log mean and variance of metrics\n",
    "            mlflow.log_metric(\"cv_f1_mean\", f1_mean)\n",
    "            mlflow.log_metric(\"cv_f1_std\", f1_std)\n",
    "            mlflow.log_metric(\"cv_accuracy_mean\", accuracy_mean)\n",
    "            mlflow.log_metric(\"cv_accuracy_std\", accuracy_std)\n",
    "            mlflow.log_metric(\"cv_precision_mean\", precision_mean)\n",
    "            mlflow.log_metric(\"cv_precision_std\", precision_std)\n",
    "            mlflow.log_metric(\"cv_recall_mean\", recall_mean)\n",
    "            mlflow.log_metric(\"cv_recall_std\", recall_std)\n",
    "            mlflow.log_metric(\"cv_auc_mean\", auc_mean)\n",
    "            mlflow.log_metric(\"cv_auc_std\", auc_std)\n",
    "\n",
    "            # Check if this model is the best based on accuracy mean\n",
    "            if accuracy_mean > best_accuracy_mean:\n",
    "                best_accuracy_mean = accuracy_mean\n",
    "                best_model_params = param_dict\n",
    "                best_model = model\n",
    "\n",
    "    # Log the best model parameters\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(best_model_params)\n",
    "        mlflow.log_metric(\"best_accuracy_mean\", best_accuracy_mean)\n",
    "\n",
    "        # Train the best model on the full training set\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "        # Calculate performance metrics on the test set\n",
    "        accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "        precision_test = precision_score(y_test, y_pred_test)\n",
    "        recall_test = recall_score(y_test, y_pred_test)\n",
    "        f1_test = f1_score(y_test, y_pred_test)\n",
    "        auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "        # Log metrics for the test set\n",
    "        mlflow.log_metric(\"test_accuracy\", accuracy_test)\n",
    "        mlflow.log_metric(\"test_precision\", precision_test)\n",
    "        mlflow.log_metric(\"test_recall\", recall_test)\n",
    "        mlflow.log_metric(\"test_f1\", f1_test)\n",
    "        mlflow.log_metric(\"test_auc\", auc_test)\n",
    "\n",
    "        # Log the best model\n",
    "        mlflow.sklearn.log_model(best_model, \"best_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19ca424-e876-4336-a2a9-66ac68726ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from src.config import *\n",
    "from src.mlflow_logging import train_and_log_model\n",
    "\n",
    "# Parameter ranges\n",
    "param_ranges = {              \n",
    "    \"max_depth\": np.arange(3, 11, 2),                \n",
    "    \"min_samples_split\": np.arange(2, 21, 3),        \n",
    "    \"min_samples_leaf\": np.arange(1, 11, 3),         \n",
    "    \"max_features\": [None, \"sqrt\"],            \n",
    "    \"random_state\": [42]                             \n",
    "}\n",
    "\n",
    "# Train and log the model\n",
    "train_and_log_model(model_class=DecisionTreeClassifier, param_ranges=param_ranges, feature_set='1', cv_folds=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
